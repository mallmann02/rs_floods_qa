{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload = {\n",
    "#     \"key\": os.getenv(\"GSE_API_KEY\"),\n",
    "#     \"cx\": os.getenv(\"GSE_CX\"),\n",
    "#     \"gl\": \"br\",\n",
    "#     \"lr\": \"lang_pt\",\n",
    "#     \"q\": \"google news enchentes rio grande do sul clicrbs\",\n",
    "#     \"num\": 5\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrap the Google News RSS feed for the latest news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchStrings = [\n",
    "    \"enchentes rio grande do sul\",\n",
    "    \"cidade atingidas pelas enchentes no RS\",\n",
    "    \"chuvas no rio grande do sul\",\n",
    "    \"danos nas cidades do vale do taquari\",\n",
    "    \"chuvas no vale do taquari\",\n",
    "    \"chuvas em lajeado\",\n",
    "    \"maior enchente em porto alegre\",\n",
    "    \"chuvas em porto alegre\",\n",
    "    \"abrigos de animais em porto alegre\",\n",
    "    \"abrigos pós enchentes em porto alegre\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will receive phrases like a user search and return the list of request objects\n",
    "def requestFactory(searchStrings:list[str]):\n",
    "    requestsList = []\n",
    "    for searchString in searchStrings:\n",
    "        searchStringFormatted = re.sub(r\"\\s+\", \"%25\", searchString)\n",
    "        r = requests.get(f\"https://news.google.com/rss/search?q={searchStringFormatted}&ceid=BR:pt-419&hl=pt-BR&gl=BR\")\n",
    "        requestsList.append(r)\n",
    "    return requestsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the response, we can parse the XML and get the items\n",
    "from xml.etree import ElementTree\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_date(date:str) -> str:\n",
    "    my_date = re.findall(r\"[a-zA-Z]{3},\\s\\d\\d\\s[a-zA-Z]{3}\\s\\d{4}\", date)[0]\n",
    "    my_date = datetime.strptime(my_date, \"%a, %d %b %Y\")\n",
    "    my_date = my_date.strftime(\"%d/%m/%Y\")\n",
    "    return my_date\n",
    "\n",
    "def scrap_rss_news_feed(rss_feeds:list[requests.Response]) -> list[dict]:\n",
    "    scrapped_news:list[dict] = []\n",
    "    for rss_feed in rss_feeds:\n",
    "        parsed = rss_feed.content.decode(\"utf-8\").replace(\"\\n\", \"\")\n",
    "        root = ElementTree.fromstring(parsed)\n",
    "        result_items = root.findall(\"./channel/item\")\n",
    "        for item in result_items[:50]:\n",
    "            scrapped_news.append({\n",
    "                \"title\": item.find(\"title\").text,\n",
    "                \"link\": item.find(\"link\").text,\n",
    "                \"description\": item.find(\"description\").text,\n",
    "                \"pubDate\": parse_date(item.find(\"pubDate\").text)\n",
    "            })\n",
    "    return scrapped_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read each news article and extract the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Publicação: 24/06/2024 às 18h53min'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanText(text):\n",
    "    # Regex pattern to match isolated special characters\n",
    "    isolatedSpecialCharacters = r'(?<![a-zA-Z0-9])[^\\w\\s]|(?<=[^\\w\\s])[^\\w\\s](?![a-zA-Z0-9])'\n",
    "    \n",
    "    \n",
    "    cleaned_text = re.sub(isolatedSpecialCharacters, '', text)\n",
    "    cleaned_text = re.sub(r'\\s\\s+', ' ', cleaned_text)\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "cleanText('Publicação: \\n\\r\\n            24/06/2024 às 18h53min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_content(scrapped_news_sources:list[dict]) -> list[str]:\n",
    "    rs_cities = open(\"rs_cities.txt\", \"r\").read().split(\"\\n\")\n",
    "    rs_cities = [city.lower() for city in rs_cities]\n",
    "    for _, news_source in tqdm(list(enumerate(scrapped_news_sources))):\n",
    "        try:\n",
    "            r = requests.get(news_source[\"link\"], timeout=5)\n",
    "            hmtl = r.content.decode(\"utf-8\")\n",
    "            soup = BeautifulSoup(hmtl, \"html.parser\")\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"Timeout error on {news_source['link']}\")\n",
    "            continue\n",
    "        except ConnectionError:\n",
    "            print(f\"Connection error on {news_source['link']}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "        # filter to only collect paragraphs\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        full_paragraphs = \" \".join([p.text for p in paragraphs])\n",
    "        full_paragraphs = cleanText(full_paragraphs)\n",
    "        full_paragraphs = full_paragraphs.encode(\"utf-8\").decode(\"utf-8\")\n",
    "        rule_identifier = getNLPWithRuler()\n",
    "        identified_cities = set()\n",
    "        for entity in rule_identifier(full_paragraphs).ents:\n",
    "            if entity.label_ == \"CITY\" and entity.text.lower() in rs_cities:\n",
    "                identified_cities.add(entity.text)\n",
    "        for p in paragraphs:\n",
    "            p_text = cleanText(p.text)\n",
    "            p_text_words = p_text.split(\" \")\n",
    "            if p_text and len(p_text_words) > 10:\n",
    "                if \"docs\" not in news_source:\n",
    "                    news_source[\"docs\"] = []\n",
    "                p_text = p_text.encode(\"utf-8\").decode(\"utf-8\")\n",
    "                news_source[\"docs\"].append(p_text)\n",
    "                news_source[\"cities\"] = list(identified_cities)\n",
    "                # paragraphs_extracted.append(p_text)\n",
    "    return scrapped_news_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading with HTML2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html2text\n",
    "h = html2text.HTML2Text()\n",
    "h.ignore_links = True\n",
    "h.ignore_images = True\n",
    "h.ignore_emphasis = True\n",
    "h.ignore_tables = True\n",
    "h.ignore_anchors = True\n",
    "h.ignore_backrefs = True\n",
    "\n",
    "print(h.handle(hmtl.decode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try filtering the data by the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "\n",
    "\n",
    "llm = HuggingFaceHub(huggingfacehub_api_token ='',\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_k\": 30,\n",
    "        \"temperature\": 0.0001,\n",
    "        \"repetition_penalty\": 1.03,\n",
    "    },\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model.invoke(\"Can you tell me a joke?\", temperature=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "context_definition = \"You are a news reviewer. You have been tasked to filter news about floods in Rio Grande do Sul and its associated impacts. Your task is filter the context for the user.\"\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "The context below is a news article about floods in Rio Grande do Sul coming from a scraped news website. Please filter the context to only include the paragraphs related to the floods in Rio Grande do Sul and its impacts.\n",
    "\n",
    "<<CONTEXT>>\n",
    "The floods in Rio Grande do Sul have caused significant damage to the region. The floods have affected many people and have caused a lot of destruction. The floods have also caused many people to lose their homes and have caused a lot of damage to the infrastructure of the region.  \n",
    "\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", context_definition),\n",
    "            (\"human\", user_prompt),\n",
    "        ])\n",
    "\n",
    "messages = template.format_messages()\n",
    "\n",
    "response = chat_model.invoke(messages, temperature=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content.split(\"</s>\")[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ChoromaDB to store the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a59990fff14b67b1c536b00933e07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: HTTPSConnectionPool(host='www.estado.rs.gov.br', port=443): Max retries exceeded with url: /defesa-civil-atualiza-balanco-das-enchentes-no-rs-2-7-18h (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xfa in position 87: invalid start byte\n",
      "Timeout error on https://news.google.com/rss/articles/CBMijgFodHRwczovL2FnZW5jaWFicmFzaWwuZWJjLmNvbS5ici9yYWRpb2FnZW5jaWEtbmFjaW9uYWwvZ2VyYWwvYXVkaW8vMjAyNC0wNy9zb2JlLXBhcmEtMTgwLW51bWVyby1kZS1tb3J0b3MtcGVsYXMtZW5jaGVudGVzLW5vLXJpby1ncmFuZGUtZG8tc3Vs0gEA?oc=5\n",
      "Timeout error on https://news.google.com/rss/articles/CBMidWh0dHBzOi8vYWdlbmNpYWJyYXNpbC5lYmMuY29tLmJyL2dlcmFsL25vdGljaWEvMjAyNC0wNS9xdWFzZS05MC1kYXMtY2lkYWRlcy1kby1ycy1mb3JhbS1hdGluZ2lkYXMtcGVsYXMtZm9ydGVzLWNodXZhc9IBAA?oc=5\n",
      "An error occurred: HTTPSConnectionPool(host='www.defesacivil.rs.gov.br', port=443): Max retries exceeded with url: /primeiro-lote-de-beneficio-do-volta-por-cima-para-atingidos-pelas-enchentes-e-pago-nesta-sexta-feira-17 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='www.estado.rs.gov.br', port=443): Max retries exceeded with url: /defesa-civil-atualiza-balanco-das-enchentes-no-rs-13-5-9h (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='www.estado.rs.gov.br', port=443): Max retries exceeded with url: /defesa-civil-atualiza-balanco-das-enchentes-no-rs-6-5-9h (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "Timeout error on https://news.google.com/rss/articles/CBMiaWh0dHBzOi8vYWdlbmNpYWJyYXNpbC5lYmMuY29tLmJyL2dlcmFsL25vdGljaWEvMjAyNC0wNi9zb2JlLXBhcmEtMTc5LXRvdGFsLWRlLW1vcnRvcy1uby1yaW8tZ3JhbmRlLWRvLXN1bNIBAA?oc=5\n",
      "Timeout error on https://news.google.com/rss/articles/CBMieGh0dHBzOi8vYWdlbmNpYWJyYXNpbC5lYmMuY29tLmJyL2dlcmFsL25vdGljaWEvMjAyNC0wNS9hdXhpbGlvLXJlY29uc3RydWNhby1jb21lY2Etc2VyLXBhZ28taG9qZS1mYW1pbGlhcy1hZmV0YWRhcy1uby1yc9IBAA?oc=5\n",
      "Timeout error on https://news.google.com/rss/articles/CBMifWh0dHBzOi8vYWdlbmNpYWJyYXNpbC5lYmMuY29tLmJyL2dlcmFsL25vdGljaWEvMjAyNC0wNy9hcnF1aXZvLW5hY2lvbmFsLWVzdGEtbm8tcnMtcGFyYS1hanVkYXItY29tLWFjZXJ2b3MtYWZldGFkb3MtcG9yLWNodXZh0gEA?oc=5\n",
      "Timeout error on https://news.google.com/rss/articles/CBMic2h0dHBzOi8vYWdlbmNpYWJyYXNpbC5lYmMuY29tLmJyL2dlcmFsL25vdGljaWEvMjAyNC0wNS9kYW5vcy1lbS1yb2Rvdmlhcy1jb21lY2FtLXNlci1hdmFsaWFkb3Mtbm8tcmlvLWdyYW5kZS1kby1zdWzSAQA?oc=5\n",
      "Timeout error on https://news.google.com/rss/articles/CBMif2h0dHBzOi8vd3d3Lm1hdGluYWxqb3JuYWxpc21vLmNvbS5ici9tYXRpbmFsL25ld3NsZXR0ZXIvZW0tdHJlcy1kaWFzLWRlLWNodXZhcy1ycy1yZWdpc3RyYS0xMS1tb3J0b3MtZS1kYW5vcy1lbS0xMTQtbXVuaWNpcGlvcy_SAQA?oc=5\n",
      "An error occurred: HTTPSConnectionPool(host='estado.rs.gov.br', port=443): Max retries exceeded with url: /governador-e-secretariado-atualizam-acoes-de-reconstrucao-de-municipios-do-vale-do-taquari (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='estado.rs.gov.br', port=443): Max retries exceeded with url: /leite-visita-roca-sales-e-reforca-apoio-do-governo-a-reconstrucao-do-municipio (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='estado.rs.gov.br', port=443): Max retries exceeded with url: /retomada-pos-enchente-no-vale-do-taquari-une-orgaos-estaduais (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='estado.rs.gov.br', port=443): Max retries exceeded with url: /estado-deposita-r-6-8-milhoes-para-municipios-e-hospitais-atingidos-pelas-enchentes (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "Timeout error on https://news.google.com/rss/articles/CBMibmh0dHBzOi8vYWdlbmNpYWJyYXNpbC5lYmMuY29tLmJyL2dlcmFsL25vdGljaWEvMjAyMy0wOS9jaWNsb25lLWRlaXhhLTIyLW1vcnRvcy1lLWNhdXNhLWVuY2hlbnRlcy1uYS1yZWdpYW8tc3Vs0gEA?oc=5\n",
      "An error occurred: HTTPSConnectionPool(host='estado.rs.gov.br', port=443): Max retries exceeded with url: /governador-visita-areas-afetadas-pelas-chuvas-nos-vales-do-taquari-e-cai-e-na-serra-gaucha (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='estado.rs.gov.br', port=443): Max retries exceeded with url: /estado-alerta-para-mais-chuvas-e-interdita-quatro-rodovias-por-riscos-de-deslizamentos (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "Timeout error on https://news.google.com/rss/articles/CBMiamh0dHBzOi8vYWdlbmNpYWJyYXNpbC5lYmMuY29tLmJyL2dlcmFsL25vdGljaWEvMjAyNC0wNS9jaHV2YXMtaW50ZW5zYXMtbmFvLWRhby10cmVndWEtbm8tcmlvLWdyYW5kZS1kby1zdWzSAQA?oc=5\n",
      "Timeout error on https://news.google.com/rss/articles/CBMie2h0dHBzOi8vYWdlbmNpYWJyYXNpbC5lYmMuY29tLmJyL2dlcmFsL25vdGljaWEvMjAyNC0wNS92YWxlLWRvLXRhcXVhcmktZXhlcmNpdG8tdmFpLXJlZmF6ZXItdHJhdmVzc2lhcy1sZXZhZGFzLXBlbGFzLWNoZWlhc9IBAA?oc=5\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /defesa-civil/noticias/defesa-civil-de-porto-alegre-atende-14-ocorrencias-devido-chuva (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /defesa-civil/noticias/prefeitura-monitora-transtornos-causados-pela-chuva (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /gca/noticias/prefeitura-atende-136-pets-em-abrigos-provisorios (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='estado.rs.gov.br', port=443): Max retries exceeded with url: /estado-traca-diagnostico-de-abrigos-que-acolhem-animais-socorridos (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /gp/noticias/forca-tarefa-da-prefeitura-reforca-atendimento-animais-na-capital (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /gca/noticias/total-de-animais-resgatados-desde-o-inicio-da-enchente-se-aproxima-de-5-mil (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /gca/noticias/feira-de-adocao-da-unidade-victoria-proporciona-novos-lares-80-animais (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /dmae/noticias/porto-alegre-recebe-sugestoes-de-holandeses-para-melhorar-protecao-contra-enchentes (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /dmlu/noticias/operacao-de-limpeza-pos-enchente-ocorre-em-15-locais-nesta-sexta-feira (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /smds/noticias/numero-de-acolhidos-em-abrigos-reduz-para-98-mil (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /smgov/noticias/prefeitura-entrega-donativos-abrigos-familiares-e-acampados-da-br-290 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /gp/noticias/melo-recebe-especialistas-holandeses-para-discutir-inundacoes (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /sms/noticias/saude-divulga-plataformas-de-teleconsultas-para-pessoas-prejudicadas-pela-enchente (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /gp/noticias/prefeitura-envia-carta-comunidade-internacional (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /smed/noticias/prefeitura-mantem-suspensao-das-aulas-em-escolas-publicas-nesta-terca-feira (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /defesa-civil/noticias/prefeitura-entrega-donativos-e-faz-atendimento-emergencial-no-arquipelago (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /smmu/noticias/central-de-transporte-enchente-realiza-mais-de-700-operacoes-de-ajuda-humanitaria (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /dmlu/noticias/limpeza-pos-enchente-ocorre-em-28-locais-nesta-quinta-feira (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /sms/noticias/equipes-mantem-atendimentos-em-saude-em-postos-avancados-abrigos-e-unidades-moveis (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /gvp/noticias/vice-prefeito-apresenta-reconstruir-porto-alegre-em-evento-nacional (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /dmae/noticias/capital-tem-65-das-ebaps-em-operacao-e-seis-bombas-da-sabesp-funcionando (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /dmlu/noticias/forca-tarefa-da-prefeitura-faz-limpeza-em-29-locais-nesta-terca-feira (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /eptc/noticias/eptc-realiza-260-escoltas-para-entregas-de-suprimentos-em-porto-alegre (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /eptc/noticias/eptc-resgata-24-cavalos-e-tres-bufalos-na-enchente (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /smoi/noticias/prefeitura-inicia-remocao-de-estrutura-do-corredor-humanitario (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /sms/noticias/clinica-da-familia-santa-marta-atende-em-unidade-movel-no-largo-zumbi (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /eptc/noticias/liberado-novo-acesso-apos-passagem-de-100-mil-veiculos-pelo-corredor-humanitario (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /demhab/noticias/prefeitura-garante-bonus-moradia-37-familias-removidas-do-dique-do-sarandi (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /pgm/noticias/pgm-lanca-boletim-informativo-sobre-orientacao-juridica-relacionada-enchente (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /sms/noticias/comeca-funcionar-o-segundo-hospital-de-campanha-da-capital (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /smtc/noticias/procon-porto-alegre-autua-19-estabelecimentos-e-notifica-43 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /eptc/noticias/eptc-libera-o-transito-na-trincheira-da-ceara (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /eptc/noticias/novos-acessos-de-entrada-e-saida-da-capital-sao-liberados-nesta-sexta-feira (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n",
      "An error occurred: HTTPSConnectionPool(host='prefeitura.poa.br', port=443): Max retries exceeded with url: /eptc/noticias/transito-na-regiao-da-rodoviaria-tera-alteracoes-partir-desta-quinta-feira (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)')))\n"
     ]
    }
   ],
   "source": [
    "news_sources = scrap_rss_news_feed(requestFactory(searchStrings))\n",
    "news_sources = list({v['link']:v for v in news_sources}.values())\n",
    "\n",
    "documents = get_news_content(news_sources)\n",
    "# with open(\"news_sources.json\", \"w\") as f:\n",
    "#     json.dump(documents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>docs</th>\n",
       "      <th>cities</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Governo do RS inaugura primeira 'cidade provis...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMinAFod...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "      <td>04/07/2024</td>\n",
       "      <td>Centro Humanitário de Acolhimento, o Recomeço,...</td>\n",
       "      <td>Canoas</td>\n",
       "      <td>5c8310daa6b34ddfae47e88084159949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Governo do RS inaugura primeira 'cidade provis...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMinAFod...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "      <td>04/07/2024</td>\n",
       "      <td>A primeira cidade provisória\" do Rio Grande do...</td>\n",
       "      <td>Canoas</td>\n",
       "      <td>318d632cd2894d9388142136b430cf03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Governo do RS inaugura primeira 'cidade provis...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMinAFod...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "      <td>04/07/2024</td>\n",
       "      <td>Inicialmente chamado de cidade provisória\" pel...</td>\n",
       "      <td>Canoas</td>\n",
       "      <td>348fb856b02f4592984482b989af4932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Governo do RS inaugura primeira 'cidade provis...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMinAFod...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "      <td>04/07/2024</td>\n",
       "      <td>Confira imagens do Centro Humanitário de Acolh...</td>\n",
       "      <td>Canoas</td>\n",
       "      <td>44218f7a8436434ba262799afa0c4e3f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Governo do RS inaugura primeira 'cidade provis...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMinAFod...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "      <td>04/07/2024</td>\n",
       "      <td>De acordo com o governo do RS, a estrutura foi...</td>\n",
       "      <td>Canoas</td>\n",
       "      <td>54780965be584e1fa759f193356dbee4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030</th>\n",
       "      <td>Porto Alegre terá abrigo exclusivo para mulher...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMirgFod...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "      <td>10/05/2024</td>\n",
       "      <td>Lauro Jardim: Quem pediu a Elon Musk ajuda par...</td>\n",
       "      <td>Canoas colorado Porto_Alegre Viamão</td>\n",
       "      <td>f4f6d9e72c8e42bebb12f83c0d4caa0f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>Porto Alegre terá abrigo exclusivo para mulher...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMirgFod...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "      <td>10/05/2024</td>\n",
       "      <td>Cinco ocorrências de estupro foram registradas...</td>\n",
       "      <td>Canoas colorado Porto_Alegre Viamão</td>\n",
       "      <td>4f77ffeaa6604f71a772e278efeb5133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>Porto Alegre terá abrigo exclusivo para mulher...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMirgFod...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "      <td>10/05/2024</td>\n",
       "      <td>Escolhas políticas estão na origem de eventos ...</td>\n",
       "      <td>Canoas colorado Porto_Alegre Viamão</td>\n",
       "      <td>bdb12f9d2da5415ba6fd67048a549cbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>Porto Alegre terá abrigo exclusivo para mulher...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMirgFod...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "      <td>10/05/2024</td>\n",
       "      <td>Os abrigos não contam com a presença permanent...</td>\n",
       "      <td>Canoas colorado Porto_Alegre Viamão</td>\n",
       "      <td>2487d0b76d6946058354fcb290be9441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>Em viagem logo após incêndio em abrigo e em me...</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMigwFod...</td>\n",
       "      <td>&lt;a href=\"https://news.google.com/rss/articles/...</td>\n",
       "      <td>07/05/2024</td>\n",
       "      <td>Cloudflare Ray ID: 89e18b07da1602e9 Your IP: C...</td>\n",
       "      <td></td>\n",
       "      <td>69a7eebe45c84f6e98727ae329559106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5035 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Governo do RS inaugura primeira 'cidade provis...   \n",
       "1     Governo do RS inaugura primeira 'cidade provis...   \n",
       "2     Governo do RS inaugura primeira 'cidade provis...   \n",
       "3     Governo do RS inaugura primeira 'cidade provis...   \n",
       "4     Governo do RS inaugura primeira 'cidade provis...   \n",
       "...                                                 ...   \n",
       "5030  Porto Alegre terá abrigo exclusivo para mulher...   \n",
       "5031  Porto Alegre terá abrigo exclusivo para mulher...   \n",
       "5032  Porto Alegre terá abrigo exclusivo para mulher...   \n",
       "5033  Porto Alegre terá abrigo exclusivo para mulher...   \n",
       "5034  Em viagem logo após incêndio em abrigo e em me...   \n",
       "\n",
       "                                                   link  \\\n",
       "0     https://news.google.com/rss/articles/CBMinAFod...   \n",
       "1     https://news.google.com/rss/articles/CBMinAFod...   \n",
       "2     https://news.google.com/rss/articles/CBMinAFod...   \n",
       "3     https://news.google.com/rss/articles/CBMinAFod...   \n",
       "4     https://news.google.com/rss/articles/CBMinAFod...   \n",
       "...                                                 ...   \n",
       "5030  https://news.google.com/rss/articles/CBMirgFod...   \n",
       "5031  https://news.google.com/rss/articles/CBMirgFod...   \n",
       "5032  https://news.google.com/rss/articles/CBMirgFod...   \n",
       "5033  https://news.google.com/rss/articles/CBMirgFod...   \n",
       "5034  https://news.google.com/rss/articles/CBMigwFod...   \n",
       "\n",
       "                                            description     pubDate  \\\n",
       "0     <a href=\"https://news.google.com/rss/articles/...  04/07/2024   \n",
       "1     <a href=\"https://news.google.com/rss/articles/...  04/07/2024   \n",
       "2     <a href=\"https://news.google.com/rss/articles/...  04/07/2024   \n",
       "3     <a href=\"https://news.google.com/rss/articles/...  04/07/2024   \n",
       "4     <a href=\"https://news.google.com/rss/articles/...  04/07/2024   \n",
       "...                                                 ...         ...   \n",
       "5030  <a href=\"https://news.google.com/rss/articles/...  10/05/2024   \n",
       "5031  <a href=\"https://news.google.com/rss/articles/...  10/05/2024   \n",
       "5032  <a href=\"https://news.google.com/rss/articles/...  10/05/2024   \n",
       "5033  <a href=\"https://news.google.com/rss/articles/...  10/05/2024   \n",
       "5034  <a href=\"https://news.google.com/rss/articles/...  07/05/2024   \n",
       "\n",
       "                                                   docs  \\\n",
       "0     Centro Humanitário de Acolhimento, o Recomeço,...   \n",
       "1     A primeira cidade provisória\" do Rio Grande do...   \n",
       "2     Inicialmente chamado de cidade provisória\" pel...   \n",
       "3     Confira imagens do Centro Humanitário de Acolh...   \n",
       "4     De acordo com o governo do RS, a estrutura foi...   \n",
       "...                                                 ...   \n",
       "5030  Lauro Jardim: Quem pediu a Elon Musk ajuda par...   \n",
       "5031  Cinco ocorrências de estupro foram registradas...   \n",
       "5032  Escolhas políticas estão na origem de eventos ...   \n",
       "5033  Os abrigos não contam com a presença permanent...   \n",
       "5034  Cloudflare Ray ID: 89e18b07da1602e9 Your IP: C...   \n",
       "\n",
       "                                   cities                              hash  \n",
       "0                                  Canoas  5c8310daa6b34ddfae47e88084159949  \n",
       "1                                  Canoas  318d632cd2894d9388142136b430cf03  \n",
       "2                                  Canoas  348fb856b02f4592984482b989af4932  \n",
       "3                                  Canoas  44218f7a8436434ba262799afa0c4e3f  \n",
       "4                                  Canoas  54780965be584e1fa759f193356dbee4  \n",
       "...                                   ...                               ...  \n",
       "5030  Canoas colorado Porto_Alegre Viamão  f4f6d9e72c8e42bebb12f83c0d4caa0f  \n",
       "5031  Canoas colorado Porto_Alegre Viamão  4f77ffeaa6604f71a772e278efeb5133  \n",
       "5032  Canoas colorado Porto_Alegre Viamão  bdb12f9d2da5415ba6fd67048a549cbd  \n",
       "5033  Canoas colorado Porto_Alegre Viamão  2487d0b76d6946058354fcb290be9441  \n",
       "5034                                       69a7eebe45c84f6e98727ae329559106  \n",
       "\n",
       "[5035 rows x 7 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def docsPostProcessor(docs=None):\n",
    "    if not docs:\n",
    "        docs = json.loads(open(\"news_sources.json\", \"r\").read())\n",
    "    docs_df = pd.DataFrame(docs)\n",
    "    docs_df = docs_df.explode(\"docs\").dropna(subset=[\"docs\"])\n",
    "    docs_df = docs_df.drop_duplicates(subset=[\"docs\"])\n",
    "    docs_df[\"cities\"] = docs_df[\"cities\"].apply(lambda x: \" \".join([city.replace(\" \", \"_\") for city in x]))\n",
    "    docs_df = docs_df.reset_index(drop=True)\n",
    "    return docs_df\n",
    "\n",
    "docs_df = docsPostProcessor(documents)\n",
    "docs_df[\"hash\"] = docs_df[\"docs\"].apply(lambda x: uuid.uuid4().hex)\n",
    "# docs_df.to_json(\"news_sources_db_ready.json\", orient=\"records\")\n",
    "docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"multi-qa-mpnet-base-cos-v1\")\n",
    "\n",
    "qa_collection = chroma_client.get_or_create_collection(\n",
    "    name=\"rs_floods_qa\",\n",
    "    embedding_function=sentence_transformer_ef,\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected metadata value to be a str, int, float or bool, got ['Canoas'] which is a list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[227], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m docs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews_sources_db_ready.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m docs\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: qa_collection\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m      4\u001b[0m     ids\u001b[38;5;241m=\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhash\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     documents\u001b[38;5;241m=\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpubDate\u001b[39m\u001b[38;5;124m\"\u001b[39m: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpubDate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcities\u001b[39m\u001b[38;5;124m\"\u001b[39m: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m     }),\n\u001b[1;32m     12\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[227], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m docs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews_sources_db_ready.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m docs\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: qa_collection\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m      4\u001b[0m     ids\u001b[38;5;241m=\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhash\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m     documents\u001b[38;5;241m=\u001b[39mx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpubDate\u001b[39m\u001b[38;5;124m\"\u001b[39m: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpubDate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcities\u001b[39m\u001b[38;5;124m\"\u001b[39m: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m     }),\n\u001b[1;32m     12\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/chromadb/api/models/Collection.py:146\u001b[0m, in \u001b[0;36mCollection.add\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd\u001b[39m(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    106\u001b[0m     ids: OneOrMany[ID],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m     uris: Optional[OneOrMany[URI]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m        ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     (\n\u001b[1;32m    140\u001b[0m         ids,\n\u001b[1;32m    141\u001b[0m         embeddings,\n\u001b[1;32m    142\u001b[0m         metadatas,\n\u001b[1;32m    143\u001b[0m         documents,\n\u001b[1;32m    144\u001b[0m         images,\n\u001b[1;32m    145\u001b[0m         uris,\n\u001b[0;32m--> 146\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_embedding_set(\n\u001b[1;32m    147\u001b[0m         ids, embeddings, metadatas, documents, images, uris\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# We need to compute the embeddings if they're not provided\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;66;03m# At this point, we know that one of documents or images are provided from the validation above\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/chromadb/api/models/Collection.py:554\u001b[0m, in \u001b[0;36mCollection._validate_embedding_set\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris, require_embeddings_or_data)\u001b[0m\n\u001b[1;32m    545\u001b[0m valid_ids \u001b[38;5;241m=\u001b[39m validate_ids(maybe_cast_one_to_many_ids(ids))\n\u001b[1;32m    546\u001b[0m valid_embeddings \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    547\u001b[0m     validate_embeddings(\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_embeddings(maybe_cast_one_to_many_embedding(embeddings))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    552\u001b[0m )\n\u001b[1;32m    553\u001b[0m valid_metadatas \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 554\u001b[0m     validate_metadatas(maybe_cast_one_to_many_metadata(metadatas))\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadatas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    557\u001b[0m )\n\u001b[1;32m    558\u001b[0m valid_documents \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    559\u001b[0m     maybe_cast_one_to_many_document(documents)\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    562\u001b[0m )\n\u001b[1;32m    563\u001b[0m valid_images \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    564\u001b[0m     maybe_cast_one_to_many_image(images) \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    565\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/chromadb/api/types.py:316\u001b[0m, in \u001b[0;36mvalidate_metadatas\u001b[0;34m(metadatas)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadatas to be a list, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadatas\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metadata \u001b[38;5;129;01min\u001b[39;00m metadatas:\n\u001b[0;32m--> 316\u001b[0m     validate_metadata(metadata)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadatas\n",
      "File \u001b[0;32m~/anaconda3/envs/ds/lib/python3.11/site-packages/chromadb/api/types.py:282\u001b[0m, in \u001b[0;36mvalidate_metadata\u001b[0;34m(metadata)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# isinstance(True, int) evaluates to True, so we need to check for bools separately\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n\u001b[0;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be a str, int, float or bool, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "\u001b[0;31mValueError\u001b[0m: Expected metadata value to be a str, int, float or bool, got ['Canoas'] which is a list"
     ]
    }
   ],
   "source": [
    "docs = pd.read_json(\"news_sources_db_ready.json\", orient=\"records\")\n",
    "\n",
    "docs.apply(lambda x: qa_collection.add(\n",
    "    ids=x[\"hash\"],\n",
    "    documents=x[\"docs\"],\n",
    "    metadatas={\n",
    "        \"title\": x[\"title\"],\n",
    "        \"link\": x[\"link\"],\n",
    "        \"pubDate\": x[\"pubDate\"],\n",
    "        \"cities\": x[\"cities\"]\n",
    "    }),\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_collection.query(query_texts=\"Qual foi o número de pessoas mortas pelas enchentes?\", n_results=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('em Maio', datetime.datetime(2024, 5, 4, 0, 0)),\n",
       " ('ano passado', datetime.datetime(2023, 5, 4, 0, 0)),\n",
       " ('em outubro', datetime.datetime(2024, 10, 4, 0, 0))]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dateparser\n",
    "from dateparser.search import search_dates\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "dateparser.parse(\"July of 2021\")\n",
    "search_dates(\"Eu me mudei em Maio do ano passado. Ela se mudou em outubro.\", languages=[\"pt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getCityPosPattern() -> list[str]:\n",
    "    rs_cities = open(\"rs_cities.txt\", \"r\").read().split(\"\\n\")\n",
    "    list_of_patterns = []\n",
    "    for city in rs_cities:\n",
    "        city_doc = nlp(city)\n",
    "        str_pattern = \" \".join([ent.pos_ for ent in city_doc])\n",
    "        list_of_patterns.append(str_pattern)\n",
    "\n",
    "    list_of_patterns = list(filter(lambda x: x not in [\"NOUN\", \"VERB\", \"PROPN\", \"ADJ\"], list_of_patterns))\n",
    "    # print(Counter(list_of_patterns).most_common(10))\n",
    "    # print(sum([count for _, count in Counter(list_of_patterns).most_common(10)]))\n",
    "    most_commons = [pattern.split(\" \") for pattern, _ in Counter(list_of_patterns).most_common(10)]\n",
    "    # print(most_commons)\n",
    "    rulerPatterns = []\n",
    "    for pattern in most_commons:\n",
    "        rulerPatterns.append({\"label\": \"CITY\", \"pattern\": [{\"POS\": pos} for pos in pattern]})\n",
    "    return rulerPatterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def getNLPWithRuler():\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "    nlp.remove_pipe(\"ner\")\n",
    "    text = \"João morou em São Jerônimo do Sul por 5 anos. Ele se mudou para Lajeado em 2019. Encantado com a cidade, ele decidiu ficar. Vale do Taquari é uma região muito bonita.\"\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "    rs_cities = open(\"rs_cities.txt\", \"r\").read().split(\"\\n\")\n",
    "    rs_cities = [city.lower() for city in rs_cities]\n",
    "\n",
    "    ruler.add_patterns(getCityPosPattern())\n",
    "    ruler.add_patterns([{\"label\": \"CITY\", \"pattern\": [{\"LOWER\": {\"IN\": rs_cities}}]}])\n",
    "\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
